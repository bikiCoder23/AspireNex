{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ed771b7-f12a-4aad-ad1e-8872e4f338a3",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c533442f-d040-4bf0-a2d8-504f580c99f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Dense, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee700a3-1c96-4c44-ae1a-abd1be02786f",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48a6028b-58b5-4670-a376-52dd9f6e4784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"creditcard.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88e1c094-6612-4421-b52e-d5019be81bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030e5a63-8e1b-4681-aba1-368723a4ebc9",
   "metadata": {},
   "source": [
    "## Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55b80457-8082-49e3-9362-64934fa48ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_amount(df, scaler):\n",
    "    df['Amount'] = scaler.transform(df['Amount'].to_numpy().reshape(-1, 1))\n",
    "    return df\n",
    "\n",
    "def normalize_time(df, time_min, time_max):\n",
    "    time = df['Time']\n",
    "    df['Time'] = (time - time_min) / (time_max - time_min)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c557c339-3c13-49b5-8093-98bffdb08550",
   "metadata": {},
   "source": [
    "## Scaling Amount and Normalizing Time data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6b80280-0de6-402a-ab76-6d794ccdc5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "scaler.fit(df['Amount'].to_numpy().reshape(-1, 1))\n",
    "\n",
    "time_min, time_max = df['Time'].min(), df['Time'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25b56cb7-ea23-4861-bae9-f3a21597612f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = scale_amount(df, scaler)\n",
    "df = normalize_time(df, time_min, time_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fec7e33-acff-4c72-a9d8-36a8a4707e5c",
   "metadata": {},
   "source": [
    "## Checking for class imbalance¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9156bba-f9a7-4d41-ba2d-450b168d5ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Class\n",
       " 0    284315\n",
       " Name: count, dtype: int64,\n",
       " Class\n",
       " 1    492\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_frauds = df.query('Class == 0')\n",
    "frauds = df.query('Class == 1')\n",
    "not_frauds['Class'].value_counts(), frauds['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75af59fe-2d92-4233-98c9-7da70e752fdf",
   "metadata": {},
   "source": [
    "## Undersampling the data for balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c78add8-036c-43f7-af35-88f4fb3a5ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "1    492\n",
       "0    492\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df = pd.concat([frauds, not_frauds.sample(len(frauds), random_state=1)])\n",
    "balanced_df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c9c042-c68f-4a5f-a38a-47f267d83b6e",
   "metadata": {},
   "source": [
    "## Randomising/shuffling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b394ec5b-2c39-4348-89c0-0fd5b1981927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>189959</th>\n",
       "      <td>0.744404</td>\n",
       "      <td>-0.865285</td>\n",
       "      <td>-0.979506</td>\n",
       "      <td>2.587540</td>\n",
       "      <td>-2.781144</td>\n",
       "      <td>-0.887336</td>\n",
       "      <td>-0.579689</td>\n",
       "      <td>-0.976755</td>\n",
       "      <td>0.132058</td>\n",
       "      <td>-1.658263</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.106978</td>\n",
       "      <td>-0.010528</td>\n",
       "      <td>-0.211955</td>\n",
       "      <td>0.021026</td>\n",
       "      <td>0.358237</td>\n",
       "      <td>-0.209483</td>\n",
       "      <td>0.062051</td>\n",
       "      <td>0.074730</td>\n",
       "      <td>-0.195626</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107637</th>\n",
       "      <td>0.408213</td>\n",
       "      <td>-2.271755</td>\n",
       "      <td>-0.457655</td>\n",
       "      <td>-2.589055</td>\n",
       "      <td>2.230778</td>\n",
       "      <td>-4.278983</td>\n",
       "      <td>0.388610</td>\n",
       "      <td>0.102485</td>\n",
       "      <td>0.813128</td>\n",
       "      <td>-1.092921</td>\n",
       "      <td>...</td>\n",
       "      <td>1.096342</td>\n",
       "      <td>0.658399</td>\n",
       "      <td>1.711676</td>\n",
       "      <td>0.333540</td>\n",
       "      <td>0.538591</td>\n",
       "      <td>-0.193529</td>\n",
       "      <td>0.258194</td>\n",
       "      <td>0.247269</td>\n",
       "      <td>11.218193</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275992</th>\n",
       "      <td>0.965502</td>\n",
       "      <td>-2.027135</td>\n",
       "      <td>-1.131890</td>\n",
       "      <td>-1.135194</td>\n",
       "      <td>1.086963</td>\n",
       "      <td>-0.010547</td>\n",
       "      <td>0.423797</td>\n",
       "      <td>3.790880</td>\n",
       "      <td>-1.155595</td>\n",
       "      <td>-0.063434</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.315105</td>\n",
       "      <td>0.575520</td>\n",
       "      <td>0.490842</td>\n",
       "      <td>0.756502</td>\n",
       "      <td>-0.142685</td>\n",
       "      <td>-0.602777</td>\n",
       "      <td>0.508712</td>\n",
       "      <td>-0.091646</td>\n",
       "      <td>8.555858</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120862</th>\n",
       "      <td>0.439760</td>\n",
       "      <td>0.531678</td>\n",
       "      <td>-1.108844</td>\n",
       "      <td>0.276972</td>\n",
       "      <td>0.386453</td>\n",
       "      <td>-1.038906</td>\n",
       "      <td>-0.810526</td>\n",
       "      <td>0.395582</td>\n",
       "      <td>-0.322635</td>\n",
       "      <td>0.068460</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>-0.824566</td>\n",
       "      <td>-0.174821</td>\n",
       "      <td>0.479535</td>\n",
       "      <td>-0.094335</td>\n",
       "      <td>0.698329</td>\n",
       "      <td>-0.130716</td>\n",
       "      <td>0.083227</td>\n",
       "      <td>5.094669</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207960</th>\n",
       "      <td>0.792328</td>\n",
       "      <td>1.878626</td>\n",
       "      <td>0.162765</td>\n",
       "      <td>-0.167433</td>\n",
       "      <td>3.465196</td>\n",
       "      <td>0.197332</td>\n",
       "      <td>1.157212</td>\n",
       "      <td>-0.676783</td>\n",
       "      <td>0.473890</td>\n",
       "      <td>-0.386278</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.217428</td>\n",
       "      <td>-0.785738</td>\n",
       "      <td>0.406279</td>\n",
       "      <td>-0.056071</td>\n",
       "      <td>-0.560484</td>\n",
       "      <td>-0.388620</td>\n",
       "      <td>-0.012717</td>\n",
       "      <td>-0.038421</td>\n",
       "      <td>-0.223713</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236229</th>\n",
       "      <td>0.860700</td>\n",
       "      <td>-1.319844</td>\n",
       "      <td>0.290232</td>\n",
       "      <td>-0.223288</td>\n",
       "      <td>-0.351133</td>\n",
       "      <td>2.003048</td>\n",
       "      <td>0.004449</td>\n",
       "      <td>2.111141</td>\n",
       "      <td>-0.155835</td>\n",
       "      <td>-1.277863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.259482</td>\n",
       "      <td>0.301030</td>\n",
       "      <td>-0.388021</td>\n",
       "      <td>-1.449786</td>\n",
       "      <td>1.720770</td>\n",
       "      <td>-0.282374</td>\n",
       "      <td>-0.106111</td>\n",
       "      <td>0.026727</td>\n",
       "      <td>2.379375</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15810</th>\n",
       "      <td>0.157716</td>\n",
       "      <td>-25.942434</td>\n",
       "      <td>14.601998</td>\n",
       "      <td>-27.368650</td>\n",
       "      <td>6.378395</td>\n",
       "      <td>-19.104033</td>\n",
       "      <td>-4.684806</td>\n",
       "      <td>-18.261393</td>\n",
       "      <td>17.052566</td>\n",
       "      <td>-3.742605</td>\n",
       "      <td>...</td>\n",
       "      <td>1.784316</td>\n",
       "      <td>-1.917759</td>\n",
       "      <td>-1.235787</td>\n",
       "      <td>0.161105</td>\n",
       "      <td>1.820378</td>\n",
       "      <td>-0.219359</td>\n",
       "      <td>1.388786</td>\n",
       "      <td>0.406810</td>\n",
       "      <td>1.089779</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569</th>\n",
       "      <td>0.007107</td>\n",
       "      <td>-0.693097</td>\n",
       "      <td>0.720897</td>\n",
       "      <td>0.487926</td>\n",
       "      <td>1.545283</td>\n",
       "      <td>-0.123343</td>\n",
       "      <td>0.151906</td>\n",
       "      <td>1.821822</td>\n",
       "      <td>-0.176592</td>\n",
       "      <td>-1.514396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200782</td>\n",
       "      <td>0.193611</td>\n",
       "      <td>0.288196</td>\n",
       "      <td>-0.081502</td>\n",
       "      <td>0.281742</td>\n",
       "      <td>-0.136080</td>\n",
       "      <td>0.050083</td>\n",
       "      <td>0.147487</td>\n",
       "      <td>3.604136</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107067</th>\n",
       "      <td>0.406674</td>\n",
       "      <td>-1.512516</td>\n",
       "      <td>1.133139</td>\n",
       "      <td>-1.601052</td>\n",
       "      <td>2.813401</td>\n",
       "      <td>-2.664503</td>\n",
       "      <td>-0.310371</td>\n",
       "      <td>-1.520895</td>\n",
       "      <td>0.852996</td>\n",
       "      <td>-1.496495</td>\n",
       "      <td>...</td>\n",
       "      <td>0.729828</td>\n",
       "      <td>0.485286</td>\n",
       "      <td>0.567005</td>\n",
       "      <td>0.323586</td>\n",
       "      <td>0.040871</td>\n",
       "      <td>0.825814</td>\n",
       "      <td>0.414482</td>\n",
       "      <td>0.267265</td>\n",
       "      <td>4.137637</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9509</th>\n",
       "      <td>0.081902</td>\n",
       "      <td>-4.710529</td>\n",
       "      <td>8.636214</td>\n",
       "      <td>-15.496222</td>\n",
       "      <td>10.313349</td>\n",
       "      <td>-4.351341</td>\n",
       "      <td>-3.322689</td>\n",
       "      <td>-10.788373</td>\n",
       "      <td>5.060381</td>\n",
       "      <td>-5.689311</td>\n",
       "      <td>...</td>\n",
       "      <td>1.990545</td>\n",
       "      <td>0.223785</td>\n",
       "      <td>0.554408</td>\n",
       "      <td>-1.204042</td>\n",
       "      <td>-0.450685</td>\n",
       "      <td>0.641836</td>\n",
       "      <td>1.605958</td>\n",
       "      <td>0.721644</td>\n",
       "      <td>-0.293440</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>984 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2         V3         V4         V5  \\\n",
       "189959  0.744404  -0.865285  -0.979506   2.587540  -2.781144  -0.887336   \n",
       "107637  0.408213  -2.271755  -0.457655  -2.589055   2.230778  -4.278983   \n",
       "275992  0.965502  -2.027135  -1.131890  -1.135194   1.086963  -0.010547   \n",
       "120862  0.439760   0.531678  -1.108844   0.276972   0.386453  -1.038906   \n",
       "207960  0.792328   1.878626   0.162765  -0.167433   3.465196   0.197332   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "236229  0.860700  -1.319844   0.290232  -0.223288  -0.351133   2.003048   \n",
       "15810   0.157716 -25.942434  14.601998 -27.368650   6.378395 -19.104033   \n",
       "1569    0.007107  -0.693097   0.720897   0.487926   1.545283  -0.123343   \n",
       "107067  0.406674  -1.512516   1.133139  -1.601052   2.813401  -2.664503   \n",
       "9509    0.081902  -4.710529   8.636214 -15.496222  10.313349  -4.351341   \n",
       "\n",
       "              V6         V7         V8        V9  ...       V21       V22  \\\n",
       "189959 -0.579689  -0.976755   0.132058 -1.658263  ... -0.106978 -0.010528   \n",
       "107637  0.388610   0.102485   0.813128 -1.092921  ...  1.096342  0.658399   \n",
       "275992  0.423797   3.790880  -1.155595 -0.063434  ... -0.315105  0.575520   \n",
       "120862 -0.810526   0.395582  -0.322635  0.068460  ...  0.000589 -0.824566   \n",
       "207960  1.157212  -0.676783   0.473890 -0.386278  ... -0.217428 -0.785738   \n",
       "...          ...        ...        ...       ...  ...       ...       ...   \n",
       "236229  0.004449   2.111141  -0.155835 -1.277863  ...  0.259482  0.301030   \n",
       "15810  -4.684806 -18.261393  17.052566 -3.742605  ...  1.784316 -1.917759   \n",
       "1569    0.151906   1.821822  -0.176592 -1.514396  ...  0.200782  0.193611   \n",
       "107067 -0.310371  -1.520895   0.852996 -1.496495  ...  0.729828  0.485286   \n",
       "9509   -3.322689 -10.788373   5.060381 -5.689311  ...  1.990545  0.223785   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28     Amount  \\\n",
       "189959 -0.211955  0.021026  0.358237 -0.209483  0.062051  0.074730  -0.195626   \n",
       "107637  1.711676  0.333540  0.538591 -0.193529  0.258194  0.247269  11.218193   \n",
       "275992  0.490842  0.756502 -0.142685 -0.602777  0.508712 -0.091646   8.555858   \n",
       "120862 -0.174821  0.479535 -0.094335  0.698329 -0.130716  0.083227   5.094669   \n",
       "207960  0.406279 -0.056071 -0.560484 -0.388620 -0.012717 -0.038421  -0.223713   \n",
       "...          ...       ...       ...       ...       ...       ...        ...   \n",
       "236229 -0.388021 -1.449786  1.720770 -0.282374 -0.106111  0.026727   2.379375   \n",
       "15810  -1.235787  0.161105  1.820378 -0.219359  1.388786  0.406810   1.089779   \n",
       "1569    0.288196 -0.081502  0.281742 -0.136080  0.050083  0.147487   3.604136   \n",
       "107067  0.567005  0.323586  0.040871  0.825814  0.414482  0.267265   4.137637   \n",
       "9509    0.554408 -1.204042 -0.450685  0.641836  1.605958  0.721644  -0.293440   \n",
       "\n",
       "        Class  \n",
       "189959      0  \n",
       "107637      1  \n",
       "275992      1  \n",
       "120862      0  \n",
       "207960      0  \n",
       "...       ...  \n",
       "236229      0  \n",
       "15810       1  \n",
       "1569        0  \n",
       "107067      1  \n",
       "9509        1  \n",
       "\n",
       "[984 rows x 31 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df = balanced_df.sample(frac=1, random_state=1)\n",
    "balanced_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50526be6-22ba-4b1f-befa-194b43357f36",
   "metadata": {},
   "source": [
    "## Spliting data into train-test validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4fb7cb4-2b19-4cca-8c31-77466fd5dd99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((700, 30), (700,), (142, 30), (142,), (142, 30), (142,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df_np = balanced_df.to_numpy()\n",
    "\n",
    "x_train, y_train = balanced_df_np[:700, :-1], balanced_df_np[:700, -1].astype(int)\n",
    "x_test, y_test = balanced_df_np[700:842, :-1], balanced_df_np[700:842, -1].astype(int)\n",
    "x_val, y_val = balanced_df_np[842:, :-1], balanced_df_np[842:, -1].astype(int)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape, x_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abaf740-007c-41cc-b11e-7ae25567d354",
   "metadata": {},
   "source": [
    "## Checking the split distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b51fdb2-87dc-468e-b1cb-3179e8acb598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1    353\n",
       " 0    347\n",
       " Name: count, dtype: int64,\n",
       " 0    73\n",
       " 1    69\n",
       " Name: count, dtype: int64,\n",
       " 0    72\n",
       " 1    70\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train).value_counts(), pd.Series(y_test).value_counts(), pd.Series(y_val).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c33e388-ce60-4d2c-bf11-8946962334c6",
   "metadata": {},
   "source": [
    "## Creating and compiling a Shallow Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc7af76d-6ee2-49a8-9a9a-ebaa1d41e914",
   "metadata": {},
   "outputs": [],
   "source": [
    "shallow_nn = Sequential([\n",
    "    InputLayer((x_train.shape[1],)),\n",
    "    Dense(2, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "checkpoint = ModelCheckpoint('shallow_nn.keras', save_best_only=True)\n",
    "shallow_nn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e85e3f22-d5f5-4a26-b4e3-31050e83510d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m62\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │             \u001b[38;5;34m8\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m3\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">73</span> (292.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m73\u001b[0m (292.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">69</span> (276.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m69\u001b[0m (276.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4</span> (16.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4\u001b[0m (16.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shallow_nn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925a63ab-0933-4c94-b5ff-3718dd19a4b1",
   "metadata": {},
   "source": [
    "## Train the model on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e6b83351-fb4c-4785-a1b5-5fb121128c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.3612 - loss: 0.9520 - val_accuracy: 0.3099 - val_loss: 0.8474\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4120 - loss: 0.8366 - val_accuracy: 0.3451 - val_loss: 0.7939\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4237 - loss: 0.7988 - val_accuracy: 0.3592 - val_loss: 0.7557\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4309 - loss: 0.7682 - val_accuracy: 0.4085 - val_loss: 0.7221\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5193 - loss: 0.7674 - val_accuracy: 0.7113 - val_loss: 0.6859\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4943 - loss: 0.7299 - val_accuracy: 0.7113 - val_loss: 0.6511\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6339 - loss: 0.6575 - val_accuracy: 0.7254 - val_loss: 0.6093\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6786 - loss: 0.6085 - val_accuracy: 0.7394 - val_loss: 0.5587\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6911 - loss: 0.5535 - val_accuracy: 0.7606 - val_loss: 0.5178\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7251 - loss: 0.5251 - val_accuracy: 0.7676 - val_loss: 0.5022\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7846 - loss: 0.4866 - val_accuracy: 0.7606 - val_loss: 0.4900\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7964 - loss: 0.5044 - val_accuracy: 0.7676 - val_loss: 0.4783\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8033 - loss: 0.4633 - val_accuracy: 0.7676 - val_loss: 0.4667\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7864 - loss: 0.4797 - val_accuracy: 0.7817 - val_loss: 0.4529\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8288 - loss: 0.4435 - val_accuracy: 0.8169 - val_loss: 0.4408\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8110 - loss: 0.4338 - val_accuracy: 0.8380 - val_loss: 0.4306\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8636 - loss: 0.4189 - val_accuracy: 0.8380 - val_loss: 0.4218\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8422 - loss: 0.4011 - val_accuracy: 0.8451 - val_loss: 0.4132\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8482 - loss: 0.4065 - val_accuracy: 0.8592 - val_loss: 0.4032\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8703 - loss: 0.3957 - val_accuracy: 0.8732 - val_loss: 0.3938\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8791 - loss: 0.3703 - val_accuracy: 0.8732 - val_loss: 0.3854\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8599 - loss: 0.3724 - val_accuracy: 0.8732 - val_loss: 0.3754\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8879 - loss: 0.3674 - val_accuracy: 0.8803 - val_loss: 0.3666\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8944 - loss: 0.3487 - val_accuracy: 0.8873 - val_loss: 0.3575\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8753 - loss: 0.3474 - val_accuracy: 0.9014 - val_loss: 0.3481\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8966 - loss: 0.3249 - val_accuracy: 0.9085 - val_loss: 0.3400\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8585 - loss: 0.3500 - val_accuracy: 0.9085 - val_loss: 0.3308\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8982 - loss: 0.3181 - val_accuracy: 0.9085 - val_loss: 0.3219\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8842 - loss: 0.3099 - val_accuracy: 0.9085 - val_loss: 0.3144\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8968 - loss: 0.2985 - val_accuracy: 0.9085 - val_loss: 0.3073\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8887 - loss: 0.3118 - val_accuracy: 0.9085 - val_loss: 0.2982\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9057 - loss: 0.2996 - val_accuracy: 0.9155 - val_loss: 0.2885\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9173 - loss: 0.2838 - val_accuracy: 0.9225 - val_loss: 0.2794\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9083 - loss: 0.2756 - val_accuracy: 0.9155 - val_loss: 0.2705\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8808 - loss: 0.2756 - val_accuracy: 0.9225 - val_loss: 0.2630\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9177 - loss: 0.2562 - val_accuracy: 0.9366 - val_loss: 0.2556\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9221 - loss: 0.2465 - val_accuracy: 0.9437 - val_loss: 0.2487\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8863 - loss: 0.2619 - val_accuracy: 0.9437 - val_loss: 0.2422\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9084 - loss: 0.2528 - val_accuracy: 0.9437 - val_loss: 0.2358\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9290 - loss: 0.2316 - val_accuracy: 0.9437 - val_loss: 0.2293\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8843 - loss: 0.2444 - val_accuracy: 0.9437 - val_loss: 0.2248\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9230 - loss: 0.2051 - val_accuracy: 0.9507 - val_loss: 0.2200\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9172 - loss: 0.2273 - val_accuracy: 0.9507 - val_loss: 0.2147\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9283 - loss: 0.2315 - val_accuracy: 0.9507 - val_loss: 0.2098\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9215 - loss: 0.2201 - val_accuracy: 0.9507 - val_loss: 0.2067\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9284 - loss: 0.2355 - val_accuracy: 0.9507 - val_loss: 0.2026\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9051 - loss: 0.2315 - val_accuracy: 0.9577 - val_loss: 0.2002\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9097 - loss: 0.2190 - val_accuracy: 0.9577 - val_loss: 0.1966\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9465 - loss: 0.1784 - val_accuracy: 0.9577 - val_loss: 0.1954\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9293 - loss: 0.2005 - val_accuracy: 0.9577 - val_loss: 0.1910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x23d494847d0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shallow_nn.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=50, callbacks=checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91b3808-a623-44ca-bf9b-20911a6f14bb",
   "metadata": {},
   "source": [
    "## Creating a prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7a3e05ba-4c63-42ea-a55f-e4025e2e7ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_net_predictions(model, x):\n",
    "  return (model.predict(x).flatten() > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8755fa-ea4d-4f5d-8dfa-cfc2e47ab0fe",
   "metadata": {},
   "source": [
    "## Classification report of the Shallow_NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9464ad98-bfe6-4593-a229-91e2680a39bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Not Fraud       0.93      0.99      0.96        72\n",
      "       Fraud       0.98      0.93      0.96        70\n",
      "\n",
      "    accuracy                           0.96       142\n",
      "   macro avg       0.96      0.96      0.96       142\n",
      "weighted avg       0.96      0.96      0.96       142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, neural_net_predictions(shallow_nn, x_val), target_names=['Not Fraud', 'Fraud']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464fe5fa-1a18-4974-b5f9-a54d1d3a4413",
   "metadata": {},
   "source": [
    "## Evaluate the model on the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d30c4653-56b0-40a6-a532-17bb07801f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Not Fraud       0.92      0.95      0.93        73\n",
      "       Fraud       0.94      0.91      0.93        69\n",
      "\n",
      "    accuracy                           0.93       142\n",
      "   macro avg       0.93      0.93      0.93       142\n",
      "weighted avg       0.93      0.93      0.93       142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, neural_net_predictions(shallow_nn, x_test), target_names=['Not Fraud', 'Fraud']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c08d665-810d-4665-bc77-1e7dfce6042d",
   "metadata": {},
   "source": [
    "## Predicting for a random instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eb0074ef-6da1-44c5-89c1-47c33e75af78",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = {'Time':37167, \n",
    "            'V1':-7.923890701,\n",
    "            'V2':-5.198360199, \n",
    "            'V3':-3.000023922, \n",
    "            'V4':4.420666202, \n",
    "            'V5':2.272193965, \n",
    "            'V6':-3.394483429, \n",
    "            'V7':-5.283435335, \n",
    "            'V8':0.131618922, \n",
    "            'V9':0.658176429, \n",
    "            'V10':-0.794993882, \n",
    "            'V11':3.266066016, \n",
    "            'V12':-2.719184951, \n",
    "            'V13':-0.124103963, \n",
    "            'V14':-5.274865819, \n",
    "            'V15':0.638575003, \n",
    "            'V16':-2.995830378, \n",
    "            'V17':-4.698433449, \n",
    "            'V18':-1.711871225, \n",
    "            'V19':3.025260992, \n",
    "            'V20':-2.169810892, \n",
    "            'V21':-0.734307917, \n",
    "            'V22':-0.59992626, \n",
    "            'V23':-4.908301176, \n",
    "            'V24':0.410170235, \n",
    "            'V25':-1.16766025, \n",
    "            'V26':0.520507647, \n",
    "            'V27':1.937421403, \n",
    "            'V28':-1.552592839, \n",
    "            'Amount':12.31}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "27bdd38e-6a5d-4466-82cd-a481dc40eb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_instance(instance, scaler, time_min, time_max):\n",
    "    processing_instance = pd.DataFrame([instance], columns=df.columns)\n",
    "    processing_instance = scale_amount(processing_instance, scaler)\n",
    "    processing_instance = normalize_time(processing_instance, time_min, time_max)\n",
    "    return processing_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "627c04cd-9595-4f5b-9d78-7470cda21253",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_instance = preprocess_instance(instance, scaler, time_min, time_max)\n",
    "required_columns = df.drop(columns=['Class']).columns.tolist()\n",
    "processed_instance = processed_instance[required_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "79a136a2-6f5b-4079-832b-74383946233b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Predicted probability: 0.9206668138504028\n",
      "Predicted class: 1\n"
     ]
    }
   ],
   "source": [
    "abs_prediction = shallow_nn.predict(processed_instance)\n",
    "prediction = (abs_prediction.flatten() > 0.5).astype(int)\n",
    "print(f'Predicted probability: {abs_prediction[0][0]}')\n",
    "print(f'Predicted class: {prediction[0]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
